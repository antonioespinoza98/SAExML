---
output: pdf_document
title: Poverty Mapping in the Age of Machine Learning
author: Marco Espinoza
email: espinozamarco70@gmail.com
organization: Comisión Económica para América Latina y el Caribe
date: 02/05/2024
editor_options: 
  chunk_output_type: console
---

De acuerdo a *Poverty Mapping in the Age of Machine Learning* se prueban tres modelos de XGBoosting machines, los cuales son:

-   Modelo XGBoost Machine con covariables de geoubicación únicamente.
-   Modelo XGBoost Machine con covariables censales únicamente.
-   Modelo XGBoost Machine con todas las covariables.

```{r}
rm(list = ls())
```

# Librerias

```{r}
x <- c('tidyverse','xgboost','gridExtra','caTools','haven','data.table',
       'Matrix')
lapply(x, require, character.only = TRUE)
```

```{r}
rm(list = ls())
```

```{r}
set.seed(1998)

options(scipen=999)
```

# Datos

```{r}
# Encuesta quitamos ingreso, lp, li y fep
encuesta_mrp <- data.table(readRDS("ingreso/datos/encuesta_mrp1.rds")) %>% 
  select(-dam,-lp,-li,-fep) %>% 
  mutate_if(is.character, as.factor) %>% 
  dplyr::rename(
    area_cat = area,
    sexo_cat = sexo,
    anoest_cat = anoest,
    discapacidad_cat = discapacidad
  )

summary(encuesta_mrp)
head(encuesta_mrp)
str(encuesta_mrp)
```

```{r}
encuesta_mrp <- readRDS("ingreso/datos/encuesta_df_agg.rds") %>% 
  data.table() |>
  select(-dam, -n) |>
  mutate_if(is.character, as.factor) %>% 
  dplyr::rename(
    area_cat = area,
    sexo_cat = sexo,
    anoest_cat = anoest,
    edad_cat = edad,
    discapacidad_cat = discapacidad
  )


str(encuesta_mrp)
```


## Matriz

```{r}
# Debido a que el XGBoosting solo toma valores numericos, se debe hacer una pequeña transformación para hacerlo funcionar.

sparse_matrix <- sparse.model.matrix(ingreso ~ ., data = encuesta_mrp)[, -1]
y = encuesta_mrp[,6]

encuesta_mrp_m <- xgb.DMatrix(data = sparse_matrix,
                              label = as.matrix(sapply(y, as.numeric)))
```


## Prueba distribución

```{r}
encuesta_mrp %>% ggplot(aes(x = ingreso)) + geom_density(stat = "density", fill = "red", alpha = 0.5) + theme_minimal() 
```

```{r}
library(MASS)

encuesta <- subset(encuesta_mrp, ingreso > 0)
ingreso <- encuesta$ingreso/10000

fitdistr(ingreso, "gamma")

ks.test(ingreso, "pgamma", shape = 1.2719982344,
        rate = 0.0459924364)
```


```{r}
ks.test(y$ingreso, "pnorm", mean(y$ingreso), sd(y$ingreso))
```


# Modelo con todas las covariables

## Modelo GBlinear

### Validación cruzada

```{r, eval=FALSE}
grid <- expand_grid(
  lambda = seq(0, 10, 1),
  lambda_bias = seq(0, 10, 1),
  alpha = seq(0, 10, 1)
)
```

```{r}
xgb_train_rmse <- numeric(nrow(grid))
xgb_test_rmse <- numeric(nrow(grid))


for(i in 1:nrow(grid)){
  xgb_untuned = xgb.cv(
    data = encuesta_mrp_m,
    booster = "gblinear",
    lambda = grid$lambda[i],
    alpha = grid$alpha[i],
    lambda_bias = grid$lambda_bias[i],
    objective = "reg:squarederror",
    eval_metric = "rmse",
    nrounds = 1000,
    early_stopping_rounds = 3, # training with a validation set will stop if the performance does not improve for k rounds (3)
    nfold = 5
  )
  
  xgb_train_rmse[i] <-
    xgb_untuned$evaluation_log$train_rmse_mean[xgb_untuned$best_iteration]
  xgb_test_rmse[i] <-
    xgb_untuned$evaluation_log$test_rmse_mean[xgb_untuned$best_iteration]
  
  cat(i, "\n")
}
```

```{r, eval=FALSE}
xgb_train_rmse <- xgb_train_rmse %>% 
  tibble() %>% 
  mutate(simulacion = seq(1:1331))

xgb_test_rmse <- xgb_test_rmse %>% 
  tibble() %>% 
  mutate(simulacion = seq(1:1331))
````

```{r}
#Guardamos las iteraciones para el primer modelo de la validación cruzada

saveRDS(xgb_train_rmse, file = "ingreso/output/xgb_train_rmse_all_linear_agg.rds")
saveRDS(xgb_test_rmse, file = "ingreso/output/xgb_test_rmse_all_linear_agg.rds")

```


```{r}
xgb_train_rmse <- readRDS("ingreso/output/xgb_train_rmse_all_linear.rds")
```

```{r}
xgb_train_rmse %>% ggplot(aes(x = simulacion, y = .)) + 
  geom_line()
```

```{r}
grid[which.min(xgb_train_rmse$.), ] 

xgb_train_rmse %>% ggplot(aes(x = simulacion, y = .)) + 
  geom_line() +
  geom_vline(xintercept = 114, linetype = 2, col = "red") +
  xlim(0, 200) +
  theme_minimal() 
```

### Modelo

vamos a ajustar el modelo con los siguientes hiperparámetros:

* Modelo agregado
- lambda = 0
- lambda_bias = 10
- alpha = 3

- lambda = 0
- lambda_bias = 9
- alpha = 0

```{r, eval=FALSE}
modelo <- xgboost(
  booster = "gblinear",
  objective = "reg:squarederror",
  lambda = 0,
  lambda_bias = 10,
  alpha = 3,
  nrounds = 1000,
  early_stopping_rounds = 3,
  data = encuesta_mrp_m
)

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_rmse
)) + geom_line() 

# Valor minimo
modelo$evaluation_log[which.min(modelo$evaluation_log$train_rmse), ]
eval <- modelo$evaluation_log

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_rmse
)) + geom_line() +
  geom_vline(xintercept = 213, col = "red", linetype = 2) + theme_minimal()
```

```{r}
saveRDS(modelo, file = "ingreso/output/modelo_agg.rds")

```

## Modelo GBtree

```{r}
rm(list = ls())
```


### Validación cruzada

```{r}
# Encuesta quitamos ingreso, lp, li y fep
encuesta_mrp <- data.table(readRDS("ingreso/datos/encuesta_mrp1.rds")) %>% 
  select(-dam,-lp,-li,-fep) %>% 
  mutate_if(is.character, as.factor) %>% 
  dplyr::rename(
    area_cat = area,
    sexo_cat = sexo,
    anoest_cat = anoest,
    discapacidad_cat = discapacidad
  )

summary(encuesta_mrp)
head(encuesta_mrp)
str(encuesta_mrp)
```

```{r}
encuesta_mrp <- readRDS("ingreso/datos/encuesta_df_agg.rds") %>% 
  data.table() |>
  select(-dam, -n) |>
  mutate_if(is.character, as.factor) %>% 
  dplyr::rename(
    area_cat = area,
    sexo_cat = sexo,
    anoest_cat = anoest,
    edad_cat = edad,
    discapacidad_cat = discapacidad
  )


str(encuesta_mrp)
```


```{r}
# Debido a que el XGBoosting solo toma valores numericos, se debe hacer una pequeña transformación para hacerlo funcionar.

sparse_matrix <- sparse.model.matrix(ingreso ~ ., data = encuesta_mrp)[, -1]
y = encuesta_mrp[,6]

encuesta_mrp_m <- xgb.DMatrix(data = sparse_matrix,
                              label = as.matrix(sapply(y, as.numeric)))
```


```{r, eval=FALSE}
grid <- expand_grid(
  eta = seq(0.10, 1, 0.05),
  max_depth = seq(6, 10, 1),
  lambda = seq(0, 5, 1),
  alpha = seq(0, 5, 1)
)
```

```{r}

xgb_train_rmse <- numeric(nrow(grid))
xgb_test_rmse <- numeric(nrow(grid))


for(i in 1:nrow(grid)){
  xgb_untuned = xgb.cv(
    data = encuesta_mrp_m,
    booster = "gbtree",
    eta = grid$eta[i],
    max_depth = grid$max_depth[i],
    lambda = grid$lambda[i],
    alpha = grid$alpha,
    objective = "reg:squarederror",
    eval_metric = "rmse",
    nrounds = 1000,
    early_stopping_rounds = 3, # training with a validation set will stop if the performance does not improve for k rounds (3)
    nfold = 5
  )
  
  xgb_train_rmse[i] <-
    xgb_untuned$evaluation_log$train_rmse_mean[xgb_untuned$best_iteration]
  xgb_test_rmse[i] <-
    xgb_untuned$evaluation_log$test_rmse_mean[xgb_untuned$best_iteration]
  
  cat(i, "\n")
}
```

```{r, eval=FALSE}
xgb_train_rmse <- xgb_train_rmse %>% 
  tibble() %>% 
  mutate(simulacion = seq(1:3420))

xgb_test_rmse <- xgb_test_rmse %>% 
  tibble() %>% 
  mutate(simulacion = seq(1:3420))
````

```{r}
#Guardamos las iteraciones para el primer modelo de la validación cruzada

saveRDS(xgb_train_rmse, file = "ingreso/output/xgb_train_rmse_all_tree_agg.rds")
saveRDS(xgb_test_rmse, file = "ingreso/output/xgb_test_rmse_all_tree_agg.rds")

```


```{r}
xgb_train_rmse <- readRDS("ingreso/output/xgb_train_rmse_all_tree.rds")
```

```{r}
xgb_train_rmse %>% ggplot(aes(x = simulacion, y = .)) + 
  geom_line()
```

```{r}
grid[which.min(xgb_train_rmse$.), ] 
grid[3207, ] 


xgb_train_rmse %>% ggplot(aes(x = simulacion, y = .)) + 
  geom_line() +
  geom_vline(xintercept = 3207, linetype = 2, col = "red") +
  xlim(2500, 3420) +
  theme_minimal() 
```

### Modelo

vamos a ajustar el modelo con los siguientes hiperparámetros:

* modelo agregado

- eta = 0.95
- depth = 10
- lambda = 0
- alpha = 2


- eta = 0.5
- depth = 10
- lambda = 0
- alpha = 0

```{r, eval=FALSE}
modelo <- xgboost(
  booster = "gbtree",
  objective = "reg:squarederror",
  eta = 0.95,
  max_depth = 10,
  lambda = 0,
  alpha = 2,
  nrounds = 1000,
  early_stopping_rounds = 3,
  data = encuesta_mrp_m
)

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_rmse
)) + geom_line() 

# Valor minimo
modelo$evaluation_log[which.min(modelo$evaluation_log$train_rmse), ]
eval <- modelo$evaluation_log

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_rmse
)) + geom_line() +
  geom_vline(xintercept = 59, col = "red", linetype = 2) + theme_minimal()
```

```{r}
saveRDS(modelo, file = "ingreso/output/modelo_tree_agg.rds")
```

# Evaluación

```{r}
rm(list = ls())
```

```{r}
modelo <- readRDS("ingreso/output/modelo_agg.rds")
modelo2 <- readRDS("ingreso/output/modelo_tree_agg.rds")
```

## Importancia de variables

```{r}
importancia <- xgb.importance(model = modelo) |>
  data.table() |>
  arrange(desc(Weight))


importancia2 <- xgb.importance(
  model = modelo2
) |>
  data.table() |>
  arrange(desc(Gain))

setdiff(importancia$Feature, importancia2$Feature)

pi1 <- xgb.ggplot.importance(importancia, rel_to_first = FALSE) 
pi2 <- xgb.ggplot.importance(importancia2, rel_to_first = FALSE)
  

grid.arrange(pi1, pi2)
```

## Predicción con la encuesta

```{r, eval=FALSE}
sparse_matrix <- sparse.model.matrix(ingreso ~ ., data = encuesta_mrp)[, -1]

y = encuesta_mrp[,2]

encuesta_mrp_m <- xgb.DMatrix(data = sparse_matrix,
                              label = as.matrix(sapply(y, as.numeric)))

pred <- predict(modelo, newdata = encuesta_mrp_m)
```

```{r}
# saveRDS(pred, file = "ingreso/output/pred_encuesta.rds")
```

```{r}
pred <- readRDS("ingreso/output/pred_encuesta.rds")

encuesta_mrp$pred <- pred
```

```{r}
matrix(c(mean(encuesta_mrp$ingreso, mean(encuesta_mrp$pred))),
       ncol = 2, dimnames = list(" " = "media", "Estimación" = c("Encuesta", "Predicción") ))
```

```{r}
pred_encuesta <- ggplot(encuesta_mrp) + 
  geom_histogram(aes(x = ingreso,fill = "Observados"), 
                 bins = 30,
                 color = "#C55A11",
                 alpha = 0.5,
                 linewidth = 0.2) +
  geom_histogram(aes(x = pred, fill = "Predichos"), 
                 bins = 30,
                 color = "#008194",
                 alpha = 0.3,
                 linewidth = 0.2) +
scale_fill_manual(values = c("#C55A11", "#008194")) +  labs(x = "Ingreso", y = " ", fill = "Valores") + xlim(0, 1000000)
  theme_classic()
```

-   De acá se puede observar que el modelo con solo las covariables geoespaciales no están brindando suficiente información al modelo, generando así un Error Cuadrático Medio mucho más alto que sus otros competidores.
-   Por otro lado, la ganancia que hay con el modelo con todas las covariables es muy poca con respecto al modelo con solo las covariables del censo.

## Predicción con el censo
```{r}
censo_mrp <- readRDS("ingreso/datos/censo_mrp1.rds") %>% ungroup() %>%
  select( area, sexo, anoest, discapacidad, edad, 
         F182013_stable_lights, X2016_crops.coverfraction,
         X2016_urban.coverfraction, X2016_gHM,
         accessibility, accessibility_walking_only,
         area1, sexo2, edad2, edad3, edad4, edad5, anoest2, anoest3,
         anoest4, discapacidad1, etnia1, 
         tiene_alcantarillado, tiene_electricidad,
         tiene_acueducto, tiene_gas, eliminar_basura,
         tiene_internet, piso_tierra,material_paredes,
         material_techo, rezago_escolar, alfabeta,
         hacinamiento,tasa_desocupacion
         ) %>% 
  dplyr::rename(
  area_cat = area,
  sexo_cat = sexo,
  anoest_cat = anoest,
  discapacidad_cat = discapacidad
)


```

```{r}
sparse_matrix <- sparse.model.matrix( ~ ., data = censo_mrp)[, -1]

censo_mrp1 <- xgb.DMatrix(data = sparse_matrix)
```

```{r, eval=FALSE}
pred <- predict(modelo, newdata = censo_mrp1)
pred2 <- predict(modelo2, newdata = censo_mrp1)
```

```{r}
saveRDS(pred, file = "ingreso/output/pred.rds")
saveRDS(pred2, file = "ingreso/output/pred2.rds")
```

