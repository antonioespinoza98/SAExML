---
output: pdf_document
title: Poverty Mapping in the Age of Machine Learning
author: Marco Espinoza
email: espinozamarco70@gmail.com
organization: Comisión Económica para América Latina y el Caribe
date: 02/05/2024
editor_options: 
  chunk_output_type: console
---


```{r}
rm(list = ls())
```

# Librerias

```{r}
x <- c('tidyverse','xgboost','gridExtra','caTools','haven','data.table',
       'Matrix','fitdistrplus')
lapply(x, require, character.only = TRUE)
```

```{r}
rm(list = ls())
```

```{r}
set.seed(1998)

options(scipen=999)
```

# Datos 

```{r}
# Encuesta quitamos ingreso, lp, li y fep
encuesta_mrp <- data.table(readRDS("ingreso/datos/encuesta_mrp1.rds")) |> 
  dplyr::select(-dam,-li,-fep) |> 
  dplyr::filter(anoest != "98") |>
  dplyr::rename(
    area_cat = area,
    sexo_cat = sexo,
    # edad_cat = edad,
    anoest_cat = anoest,
    discapacidad_cat = discapacidad
  ) |>
  mutate(pobreza = ifelse(ingreso <= lp, 1, 0)) |>
  mutate_if(is.character, as.factor) |>
  dplyr::select(-ingreso,-lp)


summary(encuesta_mrp)
head(encuesta_mrp)
str(encuesta_mrp)
```

# Modelo GBtree

```{r}
rm(list = ls())
```


## Validación cruzada

```{r}
# Debido a que el XGBoosting solo toma valores numericos, se debe hacer una pequeña transformación para hacerlo funcionar.

sparse_matrix <- sparse.model.matrix(pobreza ~ ., data = encuesta_mrp)[, -1]
 y = encuesta_mrp$pobreza
```

```{r, eval=FALSE}
grid <- expand_grid(
  eta = seq(0.30, 1, 0.10),
  max_depth = seq(6, 10, 1),
  # subsample = seq(0.5, 1, 0.10),
  lambda = seq(1, 5, 1),
  alpha = seq(0, 5, 1)
)
```

```{r}

xgb_train_auc <- numeric(nrow(grid))
xgb_test_auc <- numeric(nrow(grid))


for(i in 1:nrow(grid)){
  xgb_untuned = xgb.cv(
    data = sparse_matrix,
    label = y,
    booster = "gbtree",
    eta = grid$eta[i],
    max_depth = grid$max_depth[i],
    # subsample = grid$subsample[i],
    lambda = grid$lambda[i],
    alpha = grid$alpha[i],
    objective = "binary:logistic",
    eval_metric = "auc",
    nrounds = 1000,
    early_stopping_rounds = 3, # training with a validation set will stop if the performance does not improve for k rounds (3)
    nfold = 5
  )
  
  xgb_train_auc[i] <-
    xgb_untuned$evaluation_log$train_auc_mean[xgb_untuned$best_iteration]
  xgb_test_auc[i] <-
    xgb_untuned$evaluation_log$test_auc_mean[xgb_untuned$best_iteration]
  
  cat(i, "\n")
}
```

```{r, eval=FALSE}
xgb_train_auc <- xgb_train_auc |> 
  tibble() |> 
  mutate(simulacion = seq(1:1200))

xgb_test_auc <- xgb_test_auc |> 
  tibble() |> 
  mutate(simulacion = seq(1:1200))
````

```{r}
#Guardamos las iteraciones para el primer modelo de la validación cruzada

saveRDS(xgb_train_auc, file ="pobreza/output/xgb_train_auc.rds")
saveRDS(xgb_test_auc, file = "pobreza/output/xgb_test_auc.rds")

```

```{r}
xgb_train_auc <- readRDS("ingreso/output/xgb_train_auc.rds")
```

```{r}
xgb_train_auc |> ggplot(aes(x = simulacion, y = xgb_train_auc)) + 
  geom_line() 
```

```{r}
grid[which.max(xgb_train_auc$xgb_train_auc), ] 


xgb_train_auc |> ggplot(aes(x = simulacion, y = xgb_train_auc)) + 
  geom_line() +
  geom_vline(xintercept = 361, linetype = 2, col = "red") +
  geom_hline(yintercept = 0.7522102, linetype = 2, col = "red") +
  theme_minimal() 
```

### Modelo

vamos a ajustar el modelo con los siguientes hiperparámetros:

- eta = 0.5
- depth = 8
- lambda = 1
- alpha = 0

```{r, eval=FALSE}
modelo <- xgboost(
  booster = "gbtree",
  objective = "binary:logistic",
  eta = 0.5,
  max_depth = 8,
  lambda = 1,
  alpha = 0,
  nrounds = 1000,
  early_stopping_rounds = 3,
  eval_metric = "auc",
  data = sparse_matrix,
  label = y
)

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_auc
)) + geom_line() 


# Valor minimo
modelo$evaluation_log[which.max(modelo$evaluation_log$train_auc), ]

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_auc
)) + geom_line() + 
  theme_minimal()

```


```{r}
saveRDS(modelo, file = "pobreza/output/modelo_tree.rds")
```

# Evaluación

```{r}
rm(list = ls())
```

```{r}
modelo <- readRDS("pobreza/output/modelo_tree.rds")
```

## Importancia de variables

```{r}
importancia <- xgb.importance(model = modelo)


pi1 <- xgb.ggplot.importance(importancia, rel_to_first = FALSE) 
```

## Predicción con la encuesta

### Gtree 

Para hacer la validación del modelo, vamos a aplicar el método de validación clásico de Machine Learning. Por lo que vamos a hacer un set de datos de train y test para eventualmente poder validarlo con la tabla de confusión y con la Curva de ROC. Una vez realizado esto, se utiliza el modelo completo para la predicción a nivel de censo.

- eta = 0.5
- depth = 8
- lambda = 1
- alpha = 0

```{r}
n <- nrow(encuesta_mrp)
s <- sample(1:n, round(0.8*n))
train <- encuesta_mrp[s,]
test <- encuesta_mrp[-s,]
```

```{r}
# Debido a que el XGBoosting solo toma valores numericos, se debe hacer una pequeña transformación para hacerlo funcionar.

sparse_matrix <- sparse.model.matrix(pobreza ~ ., data = train)[, -1]
 y = train$pobreza
```

```{r, eval=FALSE}
grid <- expand_grid(
  eta = seq(0.30, 1, 0.10),
  max_depth = seq(6, 10, 1),
  # subsample = seq(0.5, 1, 0.10),
  lambda = seq(1, 5, 1),
  alpha = seq(0, 5, 1)
)
```


```{r}

xgb_train_auc <- numeric(nrow(grid))
xgb_test_auc <- numeric(nrow(grid))


for(i in 1:nrow(grid)){
  xgb_untuned = xgb.cv(
    data = sparse_matrix,
    label = y,
    booster = "gbtree",
    eta = grid$eta[i],
    max_depth = grid$max_depth[i],
    # subsample = grid$subsample[i],
    lambda = grid$lambda[i],
    alpha = grid$alpha[i],
    objective = "binary:logistic",
    eval_metric = "auc",
    nrounds = 1000,
    early_stopping_rounds = 3, # training with a validation set will stop if the performance does not improve for k rounds (3)
    nfold = 5
  )
  
  xgb_train_auc[i] <-
    xgb_untuned$evaluation_log$train_auc_mean[xgb_untuned$best_iteration]
  xgb_test_auc[i] <-
    xgb_untuned$evaluation_log$test_auc_mean[xgb_untuned$best_iteration]
  
  cat(i, "\n")
}
```

```{r, eval=FALSE}
xgb_train_auc <- xgb_train_auc |> 
  tibble() |> 
  mutate(simulacion = seq(1:1200))

xgb_test_auc <- xgb_test_auc |> 
  tibble() |> 
  mutate(simulacion = seq(1:1200))
````

```{r}
xgb_train_auc |> ggplot(aes(x = simulacion, y = xgb_train_auc)) + 
  geom_line() 
```

```{r}
grid[which.max(xgb_train_auc$xgb_train_auc), ] 


xgb_train_auc |> ggplot(aes(x = simulacion, y = xgb_train_auc)) + 
  geom_line() +
  geom_vline(xintercept = 277, linetype = 2, col = "red") +
  geom_hline(yintercept = 0.7764942, linetype = 2, col = "red") +
  theme_minimal() 
```



```{r, eval=FALSE}
modelo <- xgboost(
  booster = "gbtree",
  objective = "binary:logistic",
  eta = 0.4,
  max_depth = 10,
  lambda = 2,
  alpha = 0,
  nrounds = 1000,
  early_stopping_rounds = 3,
  eval_metric = "auc",
  data = sparse_matrix,
  label = y
)

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_auc
)) + geom_line() 
```

```{r}
sparse_matrix <- sparse.model.matrix(pobreza ~ ., data = test)[, -1]

pred <- predict(modelo, newdata = sparse_matrix)
```

```{r}
test$pred <- as.numeric(pred > 0.5) 
```

### Validación Cruzada

```{r}
confusion.mat <- table(test$pobreza, test$pred)
dimnames(confusion.mat) <- list("Reales" = c("PP", "FN"), "predichos" = c("PN", "FP"))

confusion.mat
```

- Los FP es la proporción de casos negativos que fueron clasificados como positivos. Esto quiere decir que 58 personas ~1% como pobres cuando en realidad no lo son. 
Mientras que para el caso de FN, es la proporción de casos positivos que fueron clasificados como negativos. Esto quiere decir que 998 ~17% personas fueron clasificadas no pobres cuando en realidad si lo son. 

### KS

```{r}
KS = function(pred,y) {
  predictions = prediction(pred,y) 
  des = performance(predictions,"tpr","fpr")    
  ks = max(attributes(des)$y.values[[1]]*100 - 
           attributes(des)$x.values[[1]]*100)
  return(ks)
}
```

```{r}
KS(test$pred, test$pobreza)
```

```{r}
eval <- function(y, pred){
  confu = table(y, pred)
  e = 1 - sum(diag(confu))/sum(confu)
  falsos = 1 - diag(confu)/apply(confu, 1, sum)
  error = c(e, falsos)*100
  auc = curvaROC(pred, y)$auc
  ks = KS(pred, y)
  indicadores = c(error, auc, KS)
  names(indicadores) = c("e","FP","FN","AUC","KS")
  return(list(Matriz = confu, indicadores = indicadores))
}
```


```{r}
eval(test$pobreza, as.numeric(test$pred))
```


### Curva de ROC

```{r}
predict1 <- prediction(as.numeric(test$pred), test$pobreza)
attributes(performance(predict1, "auc"))$y.values[[1]]*100
```


```{r}
library(ROCR)
library(plotly)
curvaROC = function(pred,y, grafico = F) {
  predict = prediction(pred,y) 
  auc = attributes(performance(predict,"auc"))$y.values[[1]]*100
  des = performance(predict,"tpr","fpr")
  p = NULL
  if(grafico){
    FP = attributes(des)$x.values[[1]]*100
    PP = attributes(des)$y.values[[1]]*100
    p <- plot_ly(x = FP, y = FP, name = 'Línea No Discrimina', 
                 type = 'scatter', mode = 'lines',
                 line = list(color = 'rgba(0, 0, 0, 1)', 
                             width = 4, dash = 'dot'),
                 fill = 'tozeroy',  fillcolor = 'rgba(0, 0, 0, 0)') %>% 
      add_trace(y = PP, name = paste('Curva ROC (AUC = ', round(auc,3),')', sep =""), 
                line = list(color = 'rgba(0, 0, 255, 1)', width = 4, 
                dash = 'line'),  fillcolor = 'rgba(0, 0, 255, 0.2)')%>%
      layout(title = "Curva ROC",
             xaxis = list(title = "<b>Falsos Positivos (%)<b>"),
             yaxis = list (title = "<b>Precisión Positiva (%)<b>"))
  }
  return(list(auc = auc,grafico = p))
}
```

```{r}
xgb.plot.tree(model = modelo, trees = 235)
```


```{r}
curvaROC(test$pred, test$pobreza, grafico = TRUE)
```

- La curva de ROC muestra el rendimiento de un modelo de clasificación en todos los umbrales de clasificación. 
Esta permite ver la precisión positiva contra los falsos positivos en diferentes umbrales. Lo esperado es tener más falsos positivos y más precisión positiva. 
Una forma de interpretar esto es como la probabilidad de que el modelo clasifique un ejemplo positivo aleatorio más alto que un ejemplo negativo aleatorio. Como en este caso el valor del AUC es de 0.51, esto es como tomar la decisión de clasificación con una moneda al aire. Y por lo tanto, el modelo es pobre al no ser predictivo. 


## Predicción con el censo

```{r}
rm(list = ls())
```

```{r}
modelo <- readRDS("pobreza/output/modelo_tree.rds")
```


```{r}
censo_mrp <- readRDS("ingreso/datos/cens0.rds") |> ungroup() |>
  dplyr::select(area, sexo, anoest,edad, discapacidad, 
         F182013_stable_lights, X2016_crops.coverfraction,
         X2016_urban.coverfraction, X2016_gHM,
         accessibility, accessibility_walking_only,
         area1, sexo2, edad2, edad3, edad4, edad5, anoest2, anoest3,
         anoest4, discapacidad1, etnia1, 
         tiene_alcantarillado, tiene_electricidad,
         tiene_acueducto, tiene_gas, eliminar_basura,
         tiene_internet, piso_tierra,material_paredes,
         material_techo, rezago_escolar, alfabeta,
         hacinamiento,tasa_desocupacion
         ) |>
  dplyr::filter(anoest != "98") |>
  dplyr::rename(
  area_cat = area,
  sexo_cat = sexo,
  edad_cat = edad,
  anoest_cat = anoest,
  discapacidad_cat = discapacidad
)

```

```{r}
sparse_matrix <- sparse.model.matrix( ~ ., data = censo_mrp)[, -1]
```

```{r, eval=FALSE}
pred <- predict(modelo, newdata = sparse_matrix)
```

```{r}
saveRDS(pred, file = "pobreza/output/pred.rds")
```

```{r}
pred <- readRDS("pobreza/output/pred.rds")
```

```{r}
censo_mrp$pred <- as.numeric(pred > 0.5)
```

```{r}

```





