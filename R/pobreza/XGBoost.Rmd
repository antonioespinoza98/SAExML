---
output: pdf_document
title: Poverty Mapping in the Age of Machine Learning
author: Marco Espinoza
email: espinozamarco70@gmail.com
organization: Comisión Económica para América Latina y el Caribe
date: 02/05/2024
editor_options: 
  chunk_output_type: console
---


```{r}
rm(list = ls())
```

# Librerias

```{r}
x <- c('tidyverse','xgboost','gridExtra','caTools','haven','data.table',
       'Matrix','fitdistrplus')
lapply(x, require, character.only = TRUE)
```

```{r}
rm(list = ls())
```

```{r}
set.seed(1998)

options(scipen=999)
```

# Datos 

## Datos con edad categorizada

```{r}
# Encuesta quitamos ingreso, lp, li y fep
encuesta_mrp <- data.table(readRDS("ingreso/datos/encuesta_mrp.rds")) |> 
  dplyr::select(-dam,-li,-fep) |> 
  dplyr::filter(anoest != "98") |>
  dplyr::rename(
    area_cat = area,
    sexo_cat = sexo,
    edad_cat = edad,
    anoest_cat = anoest,
    discapacidad_cat = discapacidad
  ) |>
  mutate(pobreza = ifelse(ingreso <= lp, 1, 0)) |>
  mutate_if(is.character, as.factor) |>
  dplyr::select(-ingreso,-lp)


summary(encuesta_mrp)
head(encuesta_mrp)
str(encuesta_mrp)
```

## Datos edad lineal

```{r}
# Encuesta quitamos ingreso, lp, li y fep
encuesta_mrp <- data.table(readRDS("ingreso/datos/encuesta_mrp1.rds")) |> 
  dplyr::select(-dam,-lp,-li,-fep) |> 
  dplyr::filter(anoest != "98") |>
  mutate_if(is.character, as.factor) |> 
  dplyr::rename(
    area_cat = area,
    sexo_cat = sexo,
    edad_cat = edad,
    anoest_cat = anoest,
    discapacidad_cat = discapacidad
  )

summary(encuesta_mrp)
head(encuesta_mrp)
str(encuesta_mrp)
```


## Matriz

```{r}
# Debido a que el XGBoosting solo toma valores numericos, se debe hacer una pequeña transformación para hacerlo funcionar.

sparse_matrix <- sparse.model.matrix(ingreso ~ ., data = encuesta_mrp)[, -1]
y = encuesta_mrp[,2]

encuesta_mrp_m <- xgb.DMatrix(data = sparse_matrix,
                              label = as.matrix(sapply(y, as.numeric)))
```

# Modelo GBtree

```{r}
rm(list = ls())
```


## Validación cruzada

```{r}
# Debido a que el XGBoosting solo toma valores numericos, se debe hacer una pequeña transformación para hacerlo funcionar.

sparse_matrix <- sparse.model.matrix(pobreza ~ ., data = encuesta_mrp)[, -1]
 y = encuesta_mrp$pobreza
```


```{r, eval=FALSE}
grid <- expand_grid(
  eta = seq(0.30, 1, 0.10),
  max_depth = seq(6, 10, 1),
  # subsample = seq(0.5, 1, 0.10),
  lambda = seq(1, 5, 1),
  alpha = seq(0, 5, 1)
)
```

```{r}

xgb_train_auc <- numeric(nrow(grid))
xgb_test_auc <- numeric(nrow(grid))


for(i in 1:nrow(grid)){
  xgb_untuned = xgb.cv(
    data = sparse_matrix,
    label = y,
    booster = "gbtree",
    eta = grid$eta[i],
    max_depth = grid$max_depth[i],
    # subsample = grid$subsample[i],
    lambda = grid$lambda[i],
    alpha = grid$alpha[i],
    objective = "binary:logistic",
    eval_metric = "auc",
    nrounds = 1000,
    early_stopping_rounds = 3, # training with a validation set will stop if the performance does not improve for k rounds (3)
    nfold = 5
  )
  
  xgb_train_auc[i] <-
    xgb_untuned$evaluation_log$train_auc_mean[xgb_untuned$best_iteration]
  xgb_test_auc[i] <-
    xgb_untuned$evaluation_log$test_auc_mean[xgb_untuned$best_iteration]
  
  cat(i, "\n")
}
```

```{r, eval=FALSE}
xgb_train_auc <- xgb_train_auc |> 
  tibble() |> 
  mutate(simulacion = seq(1:1200))

xgb_test_auc <- xgb_test_auc |> 
  tibble() |> 
  mutate(simulacion = seq(1:1200))
````

```{r}
#Guardamos las iteraciones para el primer modelo de la validación cruzada

saveRDS(xgb_train_auc, file ="pobreza/output/xgb_train_auc.rds")
saveRDS(xgb_test_auc, file = "pobreza/output/xgb_test_auc.rds")

```

```{r}
xgb_train_auc <- readRDS("ingreso/output/xgb_train_auc.rds")
```

```{r}
xgb_train_auc |> ggplot(aes(x = simulacion, y = xgb_train_auc)) + 
  geom_line() 
```

```{r}
grid[which.max(xgb_train_auc$xgb_train_auc), ] 


xgb_train_auc |> ggplot(aes(x = simulacion, y = xgb_train_auc)) + 
  geom_line() +
  geom_vline(xintercept = 361, linetype = 2, col = "red") +
  geom_hline(yintercept = 0.7522102, linetype = 2, col = "red") +
  theme_minimal() 
```

### Modelo

vamos a ajustar el modelo con los siguientes hiperparámetros:

* modelo edad categórica

- eta = 0.5
- depth = 8
- lambda = 1
- alpha = 0

```{r, eval=FALSE}
modelo <- xgboost(
  booster = "gbtree",
  objective = "binary:logistic",
  eta = 0.5,
  max_depth = 8,
  lambda = 1,
  alpha = 0,
  nrounds = 1000,
  early_stopping_rounds = 3,
  eval_metric = "auc",
  data = sparse_matrix,
  label = y
)

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_auc
)) + geom_line() 


# Valor minimo
modelo$evaluation_log[which.max(modelo$evaluation_log$train_auc), ]

ggplot(modelo$evaluation_log, aes(
  x = iter,
  y = train_auc
)) + geom_line() + 
  theme_minimal()

```


```{r}
saveRDS(modelo, file = "pobreza/output/modelo_tree.rds")
```

# Evaluación

```{r}
rm(list = ls())
```

```{r}
modelo <- readRDS("pobreza/output/modelo_tree.rds")
```

## Importancia de variables

```{r}
importancia <- xgb.importance(model = modelo)


pi1 <- xgb.ggplot.importance(importancia, rel_to_first = FALSE) 
```

## Predicción con la encuesta

### Gtree 

```{r}
pred <- predict(modelo2, newdata = encuesta_mrp_m)
pred <- predict(modelo3, newdata = encuesta_mrp_m)
```


```{r}

pred_encuesta <- ggplot(encuesta_mrp) +
  geom_histogram(
    aes(x = ingreso, fill = "Observados"),
    bins = 30,
    color = "#C55A11",
    alpha = 0.5,
    linewidth = 0.2
  ) +
  geom_histogram(
    aes(x = pred, fill = "Predichos"),
    bins = 30,
    color = "#008194",
    alpha = 0.3,
    linewidth = 0.2
  )  + 
  scale_fill_manual(values = c("#C55A11", "#008194")) +  
  labs(x = "Ingreso", y = " ", fill = "Valores") + 
  xlim(0, 1000000) +
  theme_classic() 

  # geom_vline(
  #   xintercept = 121000,
  #   linetype = 2,
  #   col = "red",
  #   linewidth = 1
  # )

```

```{r}
print(encuesta_mrp |>
  filter(ingreso < 121000) |>
  group_by(edad_cat, area_cat, anoest_cat, sexo_cat) |>
  summarise(
    n = n()
  ) |> 
  arrange(desc(n)), n = 76)
```


```{r}
# Media de ingreso observado

encuesta_mrp |>
  summarise(
    `ingreso medio` = mean(ingreso)
  )
```


- Entre 7 a 12 años de escolaridad, menores de 30 años y mujeres. 
- El siguiente grupo tiene las mismas características pero son hombres. 


## Predicción con el censo

```{r}
rm(list = ls())
```

```{r}
modelo <- readRDS("pobreza/output/modelo_tree.rds")
```


```{r}
censo_mrp <- readRDS("ingreso/datos/cens0.rds") |> ungroup() |>
  dplyr::select(area, sexo, anoest,edad, discapacidad, 
         F182013_stable_lights, X2016_crops.coverfraction,
         X2016_urban.coverfraction, X2016_gHM,
         accessibility, accessibility_walking_only,
         area1, sexo2, edad2, edad3, edad4, edad5, anoest2, anoest3,
         anoest4, discapacidad1, etnia1, 
         tiene_alcantarillado, tiene_electricidad,
         tiene_acueducto, tiene_gas, eliminar_basura,
         tiene_internet, piso_tierra,material_paredes,
         material_techo, rezago_escolar, alfabeta,
         hacinamiento,tasa_desocupacion
         ) |>
  dplyr::filter(anoest != "98") |>
  dplyr::rename(
  area_cat = area,
  sexo_cat = sexo,
  edad_cat = edad,
  anoest_cat = anoest,
  discapacidad_cat = discapacidad
)

```

```{r}
sparse_matrix <- sparse.model.matrix( ~ ., data = censo_mrp)[, -1]
```

```{r, eval=FALSE}
pred <- predict(modelo, newdata = sparse_matrix, type = "class") > 0.5
```

```{r}
saveRDS(pred, file = "pobreza/output/pred.rds")
```


```{r}
censo_mrp$pred <- pred
```

```{r}

censo_mrp <- censo_mrp |>
  as.character(pred) |>
  mutate(pred,
         recode(pred,
                TRUE ~ "1",
                FALSE ~ "0"))

```





